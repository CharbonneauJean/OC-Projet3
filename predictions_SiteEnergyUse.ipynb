{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 3 - Anticipez les besoins en consommation de bâtiments\n",
    "\n",
    "## Notebook d'explorations de modèles pour la prédiction de la consommation d'énergie SiteEnergyUse(kBtu)\n",
    "\n",
    "Le but de ce notebook est d'utiliser le dataset df_SEU que nous avons créer à l'étape précédente et de créer des modèles prédictifs pour les consommations énergétiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from MLUtils import DataAnalysis\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation du jeu de données\n",
    "df = pd.read_csv('data/clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Supposons que votre DataFrame s'appelle df\n",
    "X = df.drop('SiteEnergyUse(kBtu)', axis=1)  # Features\n",
    "y = df['SiteEnergyUse(kBtu)']  # Target\n",
    "\n",
    "# Diviser les données en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Modèle linéaire simple (régression linéaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Régression linéaire ne nécessite pas vraiment de GridSearch car il n'y a pas d'hyperparamètres complexes\n",
    "# Mais pour la démonstration, on va juste l'utiliser directement\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Création d'un DummyRegressor\n",
    "dummy_regressor = DummyRegressor(strategy=\"mean\")\n",
    "dummy_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred_dummy = dummy_regressor.predict(X_test)\n",
    "\n",
    "# Évaluation du DummyRegressor\n",
    "rmse_dummy = mean_squared_error(y_test, y_pred_dummy, squared=False)\n",
    "r2_dummy = r2_score(y_test, y_pred_dummy)\n",
    "\n",
    "print(f\"Dummy RMSE: {rmse_dummy}\")\n",
    "print(f\"Dummy R^2: {r2_dummy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Modèle Random Forest Regressor (GridsearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_rfr = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_grid_rfr = {\n",
    "    'n_estimators': [30,40,50],\n",
    "    'max_depth': [7,8,9],\n",
    "    'max_features': [7, 8, 9]\n",
    "}\n",
    "\n",
    "grid_search_rfr = GridSearchCV(estimator=model_rfr, param_grid=param_grid_rfr, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search_rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the grid_search_gbr.cv_results_ to a DataFrame\n",
    "results = pd.DataFrame(grid_search_rfr.cv_results_)\n",
    "\n",
    "# Select and rename columns for easier reading\n",
    "results = results[['param_n_estimators', 'param_max_depth', 'param_max_features', 'mean_test_score']]\n",
    "results.columns = ['N Estimators', 'Max Depth', 'Max Features', 'Mean Test Score']\n",
    "\n",
    "# Melt the DataFrame for easier plotting\n",
    "results_melted = results.melt(id_vars='Mean Test Score', var_name='Parameter', value_name='Value')\n",
    "\n",
    "# Create the FacetGrid\n",
    "g = sns.FacetGrid(results_melted, col='Parameter', sharex=False, sharey=False, col_wrap=2)\n",
    "g = g.map(sns.scatterplot, 'Value', 'Mean Test Score')\n",
    "\n",
    "# Add titles and adjust layout\n",
    "g.set_titles(col_template=\"{col_name}\", fontweight='bold', fontsize=14)\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('GridSearchCV Results Across Different Parameters', fontsize=16)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Assuming that grid_search.cv_results_ is defined elsewhere and contains the grid search results\n",
    "cv_results = pd.DataFrame(grid_search_rfr.cv_results_)\n",
    "\n",
    "cv_results['param_n_estimators'] = cv_results['param_n_estimators'].astype(int)\n",
    "cv_results['param_max_features'] = cv_results['param_max_features'].astype(int)\n",
    "\n",
    "pivot_df = cv_results.pivot_table(index='param_n_estimators', columns='param_max_features', values='mean_test_score')\n",
    "\n",
    "pivot_df.index = pivot_df.index.astype(str)\n",
    "pivot_df.columns = pivot_df.columns.astype(str)\n",
    "\n",
    "# Create a new DataFrame to hold the percentage format text\n",
    "text = [[f\"{val:.2%}\" for val in row] for row in pivot_df.values]\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=pivot_df.values,\n",
    "    x=pivot_df.columns.tolist(),\n",
    "    y=pivot_df.index.tolist(),\n",
    "    colorscale='RdYlGn',\n",
    "    reversescale=False,\n",
    "    text=text,  # Add the percentage text\n",
    "    texttemplate=\"%{text}\",  # Use the text from the text argument\n",
    "    hoverinfo=\"z+text\"  # Show the percentage text on hover\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Grid Search Results',\n",
    "    xaxis_title='max_features',\n",
    "    yaxis_title='n_estimators',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Assuming that grid_search.cv_results_ is defined elsewhere and contains the grid search results\n",
    "cv_results = pd.DataFrame(grid_search_rfr.cv_results_)\n",
    "\n",
    "cv_results['param_n_estimators'] = cv_results['param_n_estimators'].astype(int)\n",
    "cv_results['param_max_depth'] = cv_results['param_max_depth'].astype(int)\n",
    "\n",
    "pivot_df = cv_results.pivot_table(index='param_n_estimators', columns='param_max_depth', values='mean_test_score')\n",
    "\n",
    "pivot_df.index = pivot_df.index.astype(str)\n",
    "pivot_df.columns = pivot_df.columns.astype(str)\n",
    "\n",
    "# Create a new DataFrame to hold the percentage format text\n",
    "text = [[f\"{val:.2%}\" for val in row] for row in pivot_df.values]\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=pivot_df.values,\n",
    "    x=pivot_df.columns.tolist(),\n",
    "    y=pivot_df.index.tolist(),\n",
    "    colorscale='RdYlGn',\n",
    "    reversescale=False,\n",
    "    text=text,  # Add the percentage text\n",
    "    texttemplate=\"%{text}\",  # Use the text from the text argument\n",
    "    hoverinfo=\"z+text\"  # Show the percentage text on hover\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Grid Search Results',\n",
    "    xaxis_title='param_max_depth',\n",
    "    yaxis_title='n_estimators',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Assuming that grid_search.cv_results_ is defined elsewhere and contains the grid search results\n",
    "cv_results = pd.DataFrame(grid_search_rfr.cv_results_)\n",
    "\n",
    "cv_results['param_max_features'] = cv_results['param_max_features'].astype(int)\n",
    "cv_results['param_max_depth'] = cv_results['param_max_depth'].astype(int)\n",
    "\n",
    "pivot_df = cv_results.pivot_table(index='param_max_features', columns='param_max_depth', values='mean_test_score')\n",
    "\n",
    "pivot_df.index = pivot_df.index.astype(str)\n",
    "pivot_df.columns = pivot_df.columns.astype(str)\n",
    "\n",
    "# Create a new DataFrame to hold the percentage format text\n",
    "text = [[f\"{val:.2%}\" for val in row] for row in pivot_df.values]\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=pivot_df.values,\n",
    "    x=pivot_df.columns.tolist(),\n",
    "    y=pivot_df.index.tolist(),\n",
    "    colorscale='RdYlGn',\n",
    "    reversescale=False,\n",
    "    text=text,  # Add the percentage text\n",
    "    texttemplate=\"%{text}\",  # Use the text from the text argument\n",
    "    hoverinfo=\"z+text\"  # Show the percentage text on hover\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Grid Search Results',\n",
    "    xaxis_title='param_max_features',\n",
    "    yaxis_title='param_max_depth',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model_gbr = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# New parameter grid for GradientBoostingRegressor\n",
    "param_grid_gbr = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search_gbr = GridSearchCV(estimator=model_gbr, param_grid=param_grid_gbr, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Training the model\n",
    "grid_search_gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the grid_search_gbr.cv_results_ to a DataFrame\n",
    "results = pd.DataFrame(grid_search_gbr.cv_results_)\n",
    "\n",
    "# Filter the columns for plotting\n",
    "plot_data = results.filter(regex='(param_n_estimators|param_learning_rate|mean_test_score)')\n",
    "\n",
    "# Rename columns for easier reading\n",
    "plot_data.rename(columns={\n",
    "    'param_n_estimators': 'N Estimators',\n",
    "    'param_learning_rate': 'Learning Rate',\n",
    "    'mean_test_score': 'Mean Test Score'\n",
    "}, inplace=True)\n",
    "\n",
    "# Create a 3D scatter plot\n",
    "fig = px.scatter_3d(\n",
    "    plot_data, \n",
    "    x='N Estimators', \n",
    "    y='Learning Rate', \n",
    "    z='Mean Test Score', \n",
    "    color='Mean Test Score', \n",
    "    title='GridSearchCV Results'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show which is the best model\n",
    "print(grid_search_rfr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show which is the best model\n",
    "print(grid_search_gbr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the comparison as a table for each model\n",
    "results_rfr = pd.DataFrame(grid_search_rfr.cv_results_)\n",
    "results_gbr = pd.DataFrame(grid_search_gbr.cv_results_)\n",
    "results_rfr = results_rfr[['param_n_estimators', 'param_max_depth', 'param_max_features', 'mean_test_score']]\n",
    "results_gbr = results_gbr[['param_n_estimators', 'param_learning_rate', 'param_max_depth', 'param_max_features', 'mean_test_score']]\n",
    "\n",
    "# order by mean_test_score descending\n",
    "results_rfr = results_rfr.sort_values(by='mean_test_score', ascending=False)\n",
    "results_gbr = results_gbr.sort_values(by='mean_test_score', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_rfr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Assurez-vous que results_rfr est déjà trié par mean_test_score en ordre descendant\n",
    "# Si ce n'est pas le cas, décommentez la ligne suivante\n",
    "# results_rfr = results_rfr.sort_values(by='mean_test_score', ascending=False)\n",
    "\n",
    "# Création d'une colonne 'params' pour afficher la combinaison des paramètres dans le graphique\n",
    "results_rfr['params'] = 'Estimators: ' + results_rfr['param_n_estimators'].astype(str) + ', Depth: ' + results_rfr['param_max_depth'].astype(str) + ', Features: ' + results_rfr['param_max_features'].astype(str)\n",
    "\n",
    "# Création du graphique à barres\n",
    "fig = px.bar(results_rfr, \n",
    "             x='params', \n",
    "             y='mean_test_score',\n",
    "             labels={'params': 'Paramètres', 'mean_test_score': 'Score moyen du test'},\n",
    "             title=\"Scores moyens du test pour différentes configurations du RFR\")\n",
    "\n",
    "fig.update_layout(xaxis={'categoryorder':'total descending'})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Assurez-vous que les données sont déjà triées par mean_test_score en ordre descendant\n",
    "# Si ce n'est pas le cas, triez-les à nouveau pour être sûr\n",
    "results_gbr = results_gbr.sort_values(by='mean_test_score', ascending=False)\n",
    "\n",
    "# Création d'une colonne 'params' pour afficher la combinaison des paramètres dans le graphique\n",
    "results_gbr['params'] = 'Estimators: ' + results_gbr['param_n_estimators'].astype(str) + \\\n",
    "                        ', LR: ' + results_gbr['param_learning_rate'].astype(str) + \\\n",
    "                        ', Depth: ' + results_gbr['param_max_depth'].astype(str) + \\\n",
    "                        ', Features: ' + results_gbr['param_max_features'].astype(str)\n",
    "\n",
    "# Création du graphique à barres\n",
    "fig = px.bar(results_gbr, \n",
    "             x='params', \n",
    "             y='mean_test_score',\n",
    "             labels={'params': 'Paramètres', 'mean_test_score': 'Score moyen du test'},\n",
    "             title=\"Scores moyens du test pour différentes configurations du GBR\")\n",
    "\n",
    "fig.update_layout(xaxis={'categoryorder':'total descending'})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Prédictions avec la régression linéaire\n",
    "y_pred_linear = linear_model.predict(X_test)\n",
    "\n",
    "# Prédictions avec le meilleur modèle RandomForest trouvé par GridSearchCV\n",
    "y_pred_rf = grid_search_rfr.best_estimator_.predict(X_test)\n",
    "\n",
    "# Calcul de la RMSE pour chaque modèle\n",
    "rmse_linear = mean_squared_error(y_test, y_pred_linear, squared=False)\n",
    "rmse_rf = mean_squared_error(y_test, y_pred_rf, squared=False)\n",
    "\n",
    "print(f\"RMSE Régression Linéaire: {rmse_linear}\")\n",
    "print(f\"RMSE RandomForest: {rmse_rf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des résidus\n",
    "residuals = y_test - y_pred_rf\n",
    "\n",
    "# Visualisation des résidus\n",
    "plt.scatter(y_test, residuals)\n",
    "plt.hlines(y=0, xmin=y_test.min(), xmax=y_test.max(), colors='red')\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals Plot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir évalué plusieurs modèles, le GradientBoostingRegressor avec n_estimators=200, LR=0.1, features=sqrt et max_depth=3 a été choisi pour sa supériorité en termes de performance par rapport au modèle de référence et à la régression linéaire, tout en conservant une complexité raisonnable. Bien que le temps de calcul soit plus élevé, l'amélioration significative de la RMSE et du R² justifie ce choix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "y_pred_rf = grid_search_rfr.best_estimator_.predict(X_test)\n",
    "\n",
    "best_params = grid_search_gbr.best_params_\n",
    "\n",
    "# Vous pouvez maintenant accéder aux meilleurs paramètres individuellement\n",
    "# Par exemple :\n",
    "n_estimators = best_params['n_estimators']\n",
    "learning_rate = best_params['learning_rate']\n",
    "max_depth = best_params['max_depth']\n",
    "max_features = best_params['max_features']\n",
    "\n",
    "# Puis recréer votre meilleur modèle en utilisant ces paramètres\n",
    "best_gbr = GradientBoostingRegressor(\n",
    "    n_estimators=n_estimators,\n",
    "    learning_rate=learning_rate,\n",
    "    max_depth=max_depth,\n",
    "    max_features=max_features,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# N'oubliez pas d'entraîner votre modèle\n",
    "best_gbr.fit(X_train, y_train)\n",
    "\n",
    "# Importation des bibliothèques nécessaires\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualisation de l'importance des variables pour le modèle choisi\n",
    "feature_importances = grid_search_gbr.best_estimator_.feature_importances_\n",
    "sorted_importances = sorted(zip(df.drop('SiteEnergyUse(kBtu)', axis=1).columns, feature_importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(sorted_importances)), [importance for _, importance in sorted_importances])\n",
    "plt.xticks(range(len(sorted_importances)), [feature for feature, _ in sorted_importances], rotation=90)\n",
    "plt.title(\"Importance des variables pour le modèle choisi\")\n",
    "plt.show()\n",
    "\n",
    "# Analyse des résidus\n",
    "sns.residplot(x=y_test, y=y_pred_rf, lowess=True, color=\"g\")\n",
    "plt.xlabel(\"Valeurs prédites\")\n",
    "plt.ylabel(\"Résidus\")\n",
    "plt.title(\"Analyse des résidus pour le modèle RandomForest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table de comparaison des meilleurs modèles pour le energy use\n",
    "| Modèle | RSE | Temps d'entrainement | Taille du modèle | R² |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Régression linéaire | 0.000 | 0.000 | 0.000 | 0.000 |\n",
    "| Dummy Regressor | 0.000 | 0.000 | 0.000 | 0.000 |\n",
    "| Random Forest Regressor | 0.000 | 0.000 | 0.000 | 0.000 |\n",
    "| Gradient Boosting Regressor | 0.000 | 0.000 | 0.000 | 0.000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer une table de comparaison des modèles\n",
    " - RSE \n",
    " - Temps d'entrainement \n",
    " - Taille du modèle sur le disque avec pickle pour chacun des modèles\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oc-p3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
