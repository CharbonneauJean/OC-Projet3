{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 3 - Anticipez les besoins en consommation de bâtiments\n",
    "\n",
    "## Notebook de selections des variables importantes\n",
    "\n",
    "Le but de ce notebook est d'utiliser le dataset clean généré par l'analyse exploratoire, et de créer des modèles prédictifs pour les consommations énergétiques et l'émission de CO2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from MLUtils import DataAnalysis\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation du jeu de données\n",
    "df = pd.read_csv('data/clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalisation des données avec MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Sélection des colonnes numériques\n",
    "numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Sélection des colonnes non numériques\n",
    "non_numeric_columns = df.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "\n",
    "# Création du scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Application de la normalisation sur les colonnes numériques\n",
    "scaled_numeric_data = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# Création d'un DataFrame pour les données normalisées\n",
    "df_scaled_numeric = pd.DataFrame(scaled_numeric_data, columns=numeric_columns)\n",
    "\n",
    "# Combinaison des données numériques normalisées avec les données non numériques\n",
    "df_scaled = pd.concat([df_scaled_numeric, df[non_numeric_columns].reset_index()], axis=1)\n",
    "\n",
    "# Affichage des premières lignes pour vérifier la création de df_scaled\n",
    "df_scaled.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nous avons maintenant un dataframe contenant des colonnes normalisées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant nous intéresser à la colonne energystarscore.\n",
    "\n",
    "Notre objectif sera de voir ses correlations avec les autres colonnes, et de décider s'il convient de la conserver ou non selon ce critère."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove lines with an empty ENERGYSTARScore\n",
    "df_scaled = df_scaled.dropna(subset=['ENERGYSTARScore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Séparation des caractéristiques et des cibles\n",
    "X_with_energy_star = df_scaled.drop(['SiteEnergyUse(kBtu)', 'TotalGHGEmissions'], axis=1)\n",
    "X_without_energy_star = df_scaled.drop(['SiteEnergyUse(kBtu)', 'TotalGHGEmissions', 'ENERGYSTARScore'], axis=1)\n",
    "\n",
    "# Cibles\n",
    "y_site_energy_use = df_scaled['SiteEnergyUse(kBtu)']\n",
    "y_total_ghg_emissions = df_scaled['TotalGHGEmissions']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Séparation des ensembles d'apprentissage et de test\n",
    "X_train_with, X_test_with, y_train, y_test = train_test_split(X_with_energy_star, y_site_energy_use, test_size=0.2, random_state=42)\n",
    "X_train_without, X_test_without, _, _ = train_test_split(X_without_energy_star, y_site_energy_use, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Features correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 ) Entrainement des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Modèles linéaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) Régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Avec ENERGYSTARScore\n",
    "\n",
    "lin_reg_with_model = LinearRegression()\n",
    "\n",
    "start = time.time()\n",
    "lin_reg_with_model.fit(X_train_with, y_train)\n",
    "end = time.time()\n",
    "\n",
    "time_for_training_lin_reg_with = end - start\n",
    "\n",
    "# print the time for training\n",
    "print('Time for training with ENERGYSTARScore: ', time_for_training_lin_reg_with)\n",
    "\n",
    "y_pred_lin_reg_with = lin_reg_with_model.predict(X_test_with)\n",
    "\n",
    "mse__lin_reg_with = mean_squared_error(y_test, y_pred_lin_reg_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model as a pickle file\n",
    "import pickle\n",
    "with open('lin_reg_with_energy_star.pkl', 'wb') as file:\n",
    "    pickle.dump(lin_reg_with_model, file)\n",
    "\n",
    "# obtain the size on the disk of this model\n",
    "import os\n",
    "size_lin_reg_with = os.path.getsize('lin_reg_with_energy_star.pkl')\n",
    "\n",
    "# tranform into KB\n",
    "size_lin_reg_with = size_lin_reg_with / 1024\n",
    "\n",
    "# print the size of the model\n",
    "print('Taille du modele avec ENERGYSTARScore: ', size_lin_reg_with, 'Ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sans ENERGYSTARScore\n",
    "lin_reg_without_model = LinearRegression().fit(X_train_without, y_train)\n",
    "y_pred_without = lin_reg_without_model.predict(X_test_without)\n",
    "mse_without = mean_squared_error(y_test, y_pred_without)\n",
    "\n",
    "print(f\"MSE avec ENERGYSTARScore: {mse_with}, sans ENERGYSTARScore: {mse_without}\")\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Avec ENERGYSTARScore\n",
    "tree_reg_with_model = DecisionTreeRegressor(random_state=42).fit(X_train_with, y_train)\n",
    "y_pred_with = tree_reg_with_model.predict(X_test_with)\n",
    "mse_with = mean_squared_error(y_test, y_pred_with)\n",
    "\n",
    "# Sans ENERGYSTARScore\n",
    "tree_reg_without = DecisionTreeRegressor(random_state=42).fit(X_train_without, y_train)\n",
    "y_pred_without = tree_reg_without.predict(X_test_without)\n",
    "mse_without = mean_squared_error(y_test, y_pred_without)\n",
    "\n",
    "print(f\"MSE avec ENERGYSTARScore: {mse_with}, sans ENERGYSTARScore: {mse_without}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Séparation des ensembles d'apprentissage et de test\n",
    "X_train_with, X_test_with, y_train, y_test = train_test_split(X_with_energy_star, y_total_ghg_emissions, test_size=0.2, random_state=42)\n",
    "X_train_without, X_test_without, _, _ = train_test_split(X_without_energy_star, y_total_ghg_emissions, test_size=0.2, random_state=42)\n",
    "\n",
    "# Avec ENERGYSTARScore\n",
    "lin_reg_with_model = LinearRegression().fit(X_train_with, y_train)\n",
    "y_pred_with = lin_reg_with_model.predict(X_test_with)\n",
    "mse_with = mean_squared_error(y_test, y_pred_with)\n",
    "\n",
    "# Sans ENERGYSTARScore\n",
    "lin_reg_without_model = LinearRegression().fit(X_train_without, y_train)\n",
    "y_pred_without = lin_reg_without_model.predict(X_test_without)\n",
    "mse_without = mean_squared_error(y_test, y_pred_without)\n",
    "\n",
    "print(f\"MSE avec ENERGYSTARScore: {mse_with}, sans ENERGYSTARScore: {mse_without}\")\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Avec ENERGYSTARScore\n",
    "tree_reg_with_model = DecisionTreeRegressor(random_state=42).fit(X_train_with, y_train)\n",
    "y_pred_with = tree_reg_with_model.predict(X_test_with)\n",
    "mse_with = mean_squared_error(y_test, y_pred_with)\n",
    "\n",
    "# Sans ENERGYSTARScore\n",
    "tree_reg_without = DecisionTreeRegressor(random_state=42).fit(X_train_without, y_train)\n",
    "y_pred_without = tree_reg_without.predict(X_test_without)\n",
    "mse_without = mean_squared_error(y_test, y_pred_without)\n",
    "\n",
    "print(f\"MSE avec ENERGYSTARScore: {mse_with}, sans ENERGYSTARScore: {mse_without}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nous constatons, selon notre analyse, que la colonne ENERGYSTARScore ne semble pas avoir d'importance, ni pour l'estimation de TotalEnergyUse, ni pour celui de TotalGHGEmission, que ce soit dans le cas d'une utilisation d'un modèle linéaire ou d'un modèle non-linéaire. En effet les valeurs MSE sont les mêmes avec ou sans cette colonne. Nous allons donc supprimer cette colonne pour la suite de notre analyse de modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the ENERGYSTARScore column\n",
    "df_scaled_without_energystarscore = df_scaled.drop('ENERGYSTARScore', axis=1)\n",
    "\n",
    "# drop the index column\n",
    "df_scaled_without_energystarscore = df_scaled_without_energystarscore.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) tableau récapitulatif des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Modèle | MSE TotalEnergyUse | MSE TotalGHGEmission | Temps d'entrainement | Taille du modèle |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Régression linéaire | 0.000 | 0.000 | 0.000 | 0.000 |\n",
    "| Random Forest | 0.000 | 0.000 | 0.000 | 0.000 |\n",
    "\n",
    "On remarque qu'on obtient les meilleurs résultats avec le modèle <rfr>. Même si ce modèle est plus volumineux, il est plus performant. Nous allons donc le conserver pour la suite de notre analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Feature importance locale et globale (SHAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation des variables\n",
    "\n",
    "Nous allons maintenant faire un tableau de correlation en utilisant la méthode de Pearson des variables afin d'observer si les colonnes cibles sont correlés (ce que nous suspectons fortement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Calcul de la matrice de corrélation\n",
    "correlation_matrix = df_scaled_without_energystarscore.corr(method='pearson')\n",
    "\n",
    "correlation_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Création de la figure Plotly pour la grande matrice de corrélation\n",
    "fig_large = ff.create_annotated_heatmap(\n",
    "    z=correlation_matrix.values,\n",
    "    x=correlation_matrix.columns.tolist(),\n",
    "    y=correlation_matrix.columns.tolist(),\n",
    "    colorscale='Viridis',\n",
    "    annotation_text=correlation_matrix.round(2).values,\n",
    "    showscale=True\n",
    ")\n",
    "\n",
    "# Ajustement des dimensions de la figure pour améliorer l'affichage\n",
    "fig_large.update_layout(\n",
    "    title_text='Matrice de corrélation agrandie',\n",
    "    title_x=0.5,\n",
    "    width=1800, # Ajustement de la largeur\n",
    "    height=900, # Ajustement de la hauteur\n",
    "    autosize=False\n",
    ")\n",
    "\n",
    "# Affichage de la figure\n",
    "fig_large.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nous constatons que les colonnes TotalGHGEmission et SiteEnergyUse sont comme prévu très correllées. Nous allons donc les éliminer pour établir les modèles de prédiction de l'une ou de l'autre.\n",
    "\n",
    "Nous observons également que les colonnes suivantes sont fortement correllées :\n",
    "- SiteEUI et SiteEUIWN\n",
    "- SourceEUI et SourceEUIWN\n",
    "- SiteEnergyUse et SiteEnergyUseWN\n",
    "- NaturalGas(Kbtu) et NaturalGas(therms)\n",
    "\n",
    "Nous allons donc supprimer les colonnes WN ainsi que NaturalGas(therms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns SiteEUIWN(kBtu/sf), SourceEUIWN(kBtu/sf), SiteEnergyUseWN(kBtu), NaturalGas(therms)\n",
    "df_scaled_without_energystarscore = df_scaled_without_energystarscore.drop(['SiteEUIWN(kBtu/sf)', 'SourceEUIWN(kBtu/sf)', 'SiteEnergyUseWN(kBtu)', 'NaturalGas(therms)'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des features importance locale avec SHAP pour le SiteEnergyUse(kBtu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import shap\n",
    "\n",
    "# Séparation des caractéristiques et de la cible\n",
    "X = df_scaled_without_energystarscore.drop(['SiteEnergyUse(kBtu)', 'TotalGHGEmissions'], axis=1)\n",
    "y = df_scaled_without_energystarscore['SiteEnergyUse(kBtu)']\n",
    "\n",
    "# Division en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=62)\n",
    "\n",
    "# Entraînement du modèle\n",
    "rfr_model = RandomForestRegressor(n_estimators=100,random_state=42)\n",
    "rfr_model.fit(X_train, y_train)\n",
    "\n",
    "# Calcul des valeurs SHAP\n",
    "explainer = shap.Explainer(rfr_model, X_train)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Visualisation\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des features importance locale avec SHAP pour le TotalGHGEmissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import shap\n",
    "\n",
    "# Séparation des caractéristiques et de la cible\n",
    "X = df_scaled_without_energystarscore.drop(['SiteEnergyUse(kBtu)', 'TotalGHGEmissions'], axis=1)\n",
    "y = df_scaled_without_energystarscore['TotalGHGEmissions']\n",
    "\n",
    "# Division en ensemble d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=62)\n",
    "\n",
    "# Entraînement du modèle\n",
    "rfr_model = RandomForestRegressor(n_estimators=100,random_state=42)\n",
    "rfr_model.fit(X_train, y_train)\n",
    "\n",
    "# Calcul des valeurs SHAP\n",
    "explainer = shap.Explainer(rfr_model, X_train)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Visualisation\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the minimum value and the maximum value\n",
    "min_index = np.argmin(y_pred)\n",
    "max_index = np.argmax(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first prediction's explanation\n",
    "shap.initjs()\n",
    "shap.plots.force(shap_values[min_index, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first prediction's explanation\n",
    "shap.initjs()\n",
    "shap.plots.force(shap_values[max_index, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first prediction's explanation\n",
    "shap.initjs()\n",
    "shap.plots.force(shap_values[0, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.force(shap_values[15, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features importance globales pour le calcul du SiteEnergyUse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "\n",
    "y = df_scaled_without_energystarscore['SiteEnergyUse(kBtu)']  # Supposition pour l'exemple\n",
    "X = df_scaled_without_energystarscore.drop(columns=['SiteEnergyUse(kBtu)', 'TotalGHGEmissions'])\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement du modèle RandomForestRegressor\n",
    "rfr_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rfr_model.fit(X_train, y_train)\n",
    "\n",
    "# Obtention de l'importance des caractéristiques\n",
    "feature_importances = rfr_model.feature_importances_\n",
    "features = X.columns\n",
    "importances_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "\n",
    "# Visualisation de l'importance des caractéristiques avec Plotly\n",
    "fig = px.bar(importances_df.sort_values('Importance', ascending=False), \n",
    "             x='Importance', \n",
    "             y='Feature', \n",
    "             height=800,\n",
    "             title=\"Feature Importances using RandomForestRegressor\",\n",
    "             labels={'Feature':'Feature', 'Importance':'Importance'},\n",
    "             orientation='h')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nos analyses des features importances locales et globales nous permettent de choisir les variables importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframes with columns that have an importance greater than 0.01\n",
    "# columns 'NaturalGas(kBtu)', 'SteamUse(kBtu)', 'GHGEmissionsIntensity', 'NumberofBuildings', 'NumberofFloors', 'Age', 'SiteEUI(kBtu/sf)', 'SourceEUI(kBtu/sf)', 'SiteEnergyUse(kBtu)'\n",
    "df_SEU = df_scaled_without_energystarscore[['NaturalGas(kBtu)', 'SteamUse(kBtu)', 'GHGEmissionsIntensity', 'NumberofBuildings', 'NumberofFloors', 'Age', 'SiteEUI(kBtu/sf)', 'SourceEUI(kBtu/sf)', 'SiteEnergyUse(kBtu)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features importance pour le calcul du TotalGHGEmissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "\n",
    "y = df_scaled_without_energystarscore['TotalGHGEmissions']  # Supposition pour l'exemple\n",
    "X = df_scaled_without_energystarscore.drop(columns=['TotalGHGEmissions', 'SiteEnergyUse(kBtu)'])\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement du modèle RandomForestRegressor\n",
    "rfr_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rfr_model.fit(X_train, y_train)\n",
    "\n",
    "# Obtention de l'importance des caractéristiques\n",
    "feature_importances = rfr_model.feature_importances_\n",
    "features = X.columns\n",
    "importances_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "\n",
    "# Visualisation de l'importance des caractéristiques avec Plotly\n",
    "fig = px.bar(importances_df.sort_values('Importance', ascending=False), \n",
    "             x='Importance', \n",
    "             y='Feature', \n",
    "             height=800,\n",
    "             title=\"Feature Importances using RandomForestRegressor\",\n",
    "             labels={'Feature':'Feature', 'Importance':'Importance'},\n",
    "             orientation='h')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nos analyses des features importances locales et globales nous permettent de choisir les variables importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe, with data from df_scaled_without_energystarscore with columns that have an importance greater than 0.01\n",
    "\n",
    "df_TGE = df_scaled_without_energystarscore[['NaturalGas(kBtu)', 'SteamUse(kBtu)', 'GHGEmissionsIntensity', 'NumberofBuildings', 'NumberofFloors', 'Age', 'SiteEUI(kBtu/sf)', 'TotalGHGEmissions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nous avons maintenant nos deux datasets sur lesquels nous allons créer nos modèles\n",
    "- Pour SiteEnergyUse, nous avons le dataset df_SEU\n",
    "- Pour TotalGHGEmissions, nous avons le data df_TGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataAnalysis.show_columns_population(df_SEU, type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataAnalysis.show_columns_population(df_TGE, type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nos datasets sont prêts pour l'exploration des modèles consécutive. Il n'y a pas de valeur manquante, les valeurs sont normalisées, nous avons pris en compte l'importance des variables et leur correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nous avons 2524 observations pour chacun des datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TGE.to_csv('data/df_TGE.csv', index=False)\n",
    "df_SEU.to_csv('data/df_SEU.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oc-p3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
